{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0,
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Important: We highly recommend that you download and then upload this notebook to Google Colab on Google Drive. That way, you can take advantage of GPU hardware to accelerate training. You can submit the notebook file with outputs shown directly to Gradescope.**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "from torch.utils.data import DataLoader, random_split\n",
                "from torch.utils.data.dataset import TensorDataset\n",
                "from collections import defaultdict\n",
                "from tqdm import tqdm\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "import torch.nn.functional as F\n",
                "import torch.optim as optim\n",
                "import torch.nn as nn\n",
                "import numpy as np\n",
                "import random\n",
                "\n",
                "import warnings\n",
                "import torch\n",
                "import os\n",
                "\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"Device used: {device}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "def display_data_loader_images(\n",
                "    dataset: TensorDataset\n",
                ") -\u003e None:\n",
                "    \"\"\"\n",
                "        Display 10 random images with this function. If you want to\n",
                "        display a different set of images, simply call this\n",
                "        function again on the same DataLoader object.\n",
                "\n",
                "        Args\n",
                "            dataset: a TensorDataset object containing\n",
                "                Imagenette images from Problem Set 6.\n",
                "    \"\"\"\n",
                "\n",
                "    label_map = {\n",
                "        0: \"cassette\",\n",
                "        1: \"chainsaw\",\n",
                "        2: \"church\",\n",
                "        3: \"english springer\",\n",
                "        4: \"french horn\",\n",
                "        5: \"garbage truck\",\n",
                "        6: \"gas pump\",\n",
                "        7: \"golf ball\",\n",
                "        8: \"parachute\",\n",
                "        9: \"tench\",\n",
                "    }\n",
                "\n",
                "    assert(type(dataset) == TensorDataset)\n",
                "    random_images = [dataset[i] for i in random.sample(range(len(dataset)), 10)]\n",
                "    fig, axes = plt.subplots(2, 5, figsize=(10, 4))\n",
                "    for i in range(10):\n",
                "        ax = axes[i // 5, i % 5]\n",
                "        image, label = random_images[i]\n",
                "        ax.imshow(np.moveaxis(image.numpy().squeeze(), 0, -1))\n",
                "        ax.axis(\"off\")\n",
                "        ax.set_title(f\"{label_map[label.item()]}\")\n",
                "\n",
                "    plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Image Classification\n",
                "\n",
                "For this last assignment, you will use PyTorch to implement a convolutional neural network image classifier. You will walk through the steps of setting up data, implementing training and validation code, specifying parameters, and learning and evaluating a model.\n",
                "\n",
                "First, we will need to import the Imagenette data. In order to run it, download both `imagenette_train.pt` and `imagenett_test.pt` from the shared Google Drive [link](https://drive.google.com/drive/folders/1K8wD1dhGJ2ULG8KoBjDs6uzh5UwmfNw-?usp=sharing). Then, when you have saved them to a directory in your own Google Drive, run the function `import_imagenette_data()`, calling `/content/drive/MyDrive/\u003cDIR_NAME\u003e/` as a parameter."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "def import_imagenette_data(\n",
                "    dir: str = \"/content/drive/MyDrive/\"\n",
                "):\n",
                "\n",
                "    from google.colab import drive\n",
                "    drive.mount('/content/drive')\n",
                "    print(\"Downloading Imagenette Data...\", end=\" \")\n",
                "    train_data = torch.load(os.path.join(dir, \"imagenette_train.pt\"))\n",
                "    test_data = torch.load(os.path.join(dir, \"imagenette_test.pt\"))\n",
                "    print(\"Download Complete!\")\n",
                "\n",
                "    return train_data, test_data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "BASE_DIR = \"/content/drive/MyDrive/\"\n",
                "DIR_NAME = \"ai-hw-5/\"\n",
                "FULL_DIR = os.path.join(BASE_DIR, DIR_NAME)\n",
                "all_train_data, test_data = import_imagenette_data(FULL_DIR)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If you'd like to look at any of the images, you can use the provided `display_data_loader_images` function to do so, as demonstrated below."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "display_data_loader_images(all_train_data) # insert your dataset of interest here"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 1: `CNN` Class (8 points)\n",
                "\n",
                "Our first task will be to write a class that stores a convolutional neural network model. Write the `__init__()` function. It should define two `nn.Sequential` attributes: `self.conv` and `self.fc`. `self.conv` should be a convolutional sequence; `self.fc` should be a simple multi-layer perceptron.\n",
                "\n",
                "* The first layer of `self.conv` is a 2D convolutional layer that takes the specified number of in-channels, 16 out-channels, a kernel size of 8, and a stride length of 4. Follow this with a rectified linear unit, and then a 2D max pooling layer with kernel size 2 and stride length 2. Finally, repeat these three layers, but this time change the convolutional layer to have 16 in-channels, 32 out-channels, a kernel size of 4, and a stride length of 2.\n",
                "\n",
                "* `self.fc` should consist of a flattening layer to flatten the output of `self.conv`. Then add a linear layer, a rectified linear unit, a linear layer, a rectified linear unit, and one final linear layer. The input dimension of `self.fc` should be the same as the output dimension of `self.conv`. The output dimension of `self.fc` should be the number of classes. For all other intermediate input/output dimensions, fix them to any number you'd like (we recommend anything above 256).\n",
                "\n",
                "* Be sure to call `super()` so that `CNN` can access methods form `nn.Module`.\n",
                "\n",
                "* Be sure to send each of the constructed sequences to the specified device."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "class CNN(nn.Module):\n",
                "    def __init__(\n",
                "            self,\n",
                "            in_channels: int = 3,\n",
                "            num_classes: int = 10,\n",
                "            device: str = \"cpu\",\n",
                "    ):\n",
                "        # TODO\n",
                "        pass\n",
                "\n",
                "    def forward(\n",
                "            self,\n",
                "            x,\n",
                "    ):\n",
                "        return self.fc(self.conv(x))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 2: Data and Learning Setup (6 points)\n",
                "\n",
                "At the beginning, we imported two datasets: ```all_train_data``` and ```test_data```. Store the training data and test data in two separate `DataLoader` objects, one for training and one for validation. Specify a batch size of 32. Then print out the number of data points in each dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In order to train and evaluate our model, we need an optimizer and a criterion. For the former, we will use a procedure called [Adam](https://arxiv.org/abs/1412.6980) (ADAptive Moment estimation). Adam works similarly to stochastic gradient descent, except it _adapts_ its step size according to _momentum_, which is a measure of how close it is to a local minimum.\n",
                "\n",
                "For the criterion, we will use cross-entropy loss, which just corresponds to the log loss that we saw in class for logistic regression.\n",
                "\n",
                "* First initialize your CNN model, setting the number of input channels to 3 (one for each color channel), the number of classes to 10, and the device to the device you are currently using.\n",
                "\n",
                "* Initialize an optimizer variable using the Adam optimizer from the PyTorch library. Set the learning rate to $1 \\times 10^{-4}$.\n",
                "\n",
                "* Initialize a criterion variable using the cross-entropy loss criterion from the PyTorch library."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 3: `train()` Function (16 points)\n",
                "\n",
                "Now we will implement ```train()```, the main function that will iterate through our data to learn the model. It takes in 7 parameters:\n",
                "\n",
                "1. ```train_data```: this is a DataLoader object containing the training data.\n",
                "2. ```val_data```: this is a DataLoader object containing the validation data.\n",
                "3. ```model```: this is the CNN model that you instantiated to be trained.\n",
                "4. ```criterion```: this is the criterion to be used during training.\n",
                "5. ```optimizer```: this is the optimizer to be used during training.\n",
                "6. ```num_epochs```: this is the number of epochs to train for.\n",
                "7. ```device```: this is the device to send all computations to.\n",
                "\n",
                "To train, you will iterate over the specified number of epochs. In each epoch, you will execute the training phase by iterating through the DataLoaders, calculating losses, and computing gradient update steps. You will then repeat these steps for the validation phase, but without the step of computing gradients and updating the model.\n",
                "\n",
                "Within this function, you should also update the defined `info` dictionary. It contains four lists, updated at the end of each epoch: `\"train_losses\"`, `\"train_accuracies\"`, `\"val_losses\"`, `\"val_accuracies\"`. Return this dictionary when this function completes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train(\n",
                "        train_data: DataLoader,\n",
                "        val_data: DataLoader,\n",
                "        model: nn.Module,\n",
                "        criterion: nn.Module,\n",
                "        optimizer: optim.Optimizer,\n",
                "        num_epochs: int,\n",
                "        device: str = \"cpu\",\n",
                "):\n",
                "    info = defaultdict(list)\n",
                "\n",
                "    # TODO\n",
                "\n",
                "    return info"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Once you have this function implemented, call it to train the model with all of our defined parameters. Use 50 epochs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 4: Loss and Accuracy Curves (6 points)\n",
                "\n",
                "Use the ```plot_info()``` function below to plot the training and validation losses and accuracies in `info`. Then briefly answer the following questions.\n",
                "\n",
                "* Give a qualitative description of the training and validation loss curves. What do you notice about the loss curves in relation to each other?\n",
                "\n",
                "* Let's focus on the validation loss and accuracy curves. Around how many epochs does the model begin to overfit? What do the loss and accuracy curves look like when this happens?\n",
                "\n",
                "* Let's zoom in once more on the validation loss curve only. How does this curve inform you on when your model has the best performance without overfitting the training data?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_info(info):\n",
                "    fig, ax = plt.axes = plt.subplots(1, 2, figsize=(10, 3))\n",
                "    ax[0].plot(info[\"train_losses\"], label=\"Train Loss\")\n",
                "    ax[0].plot(info[\"val_losses\"], label=\"Validation Loss\")\n",
                "    ax[0].set_xlabel(\"Epochs\")\n",
                "    ax[0].set_ylabel(\"Loss\")\n",
                "    ax[0].set_title(\"Loss vs. Epochs\")\n",
                "    ax[0].legend()\n",
                "    ax[1].plot(info[\"train_accuracies\"], label=\"Train Accuracy\")\n",
                "    ax[1].plot(info[\"val_accuracies\"], label=\"Validation Accuracy\")\n",
                "    ax[1].set_xlabel(\"Epochs\")\n",
                "    ax[1].set_ylabel(\"Accuracy\")\n",
                "    ax[1].set_title(\"Accuracy vs. Epochs\")\n",
                "    ax[1].legend()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                ""
            ]
        }
    ]
}
